{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0vIZOS__N5y"
      },
      "source": [
        "# ENTENDIENDO EL MÓDULO \"LSTM\" EN KERAS\n",
        "\n",
        "En este tutorial vamos a entender cómo usar las principales opciones del módulo \"LSTM\" de Keras para la creación de Redes LSTM.\n",
        "\n",
        "Contenido:\n",
        "1. [Redes LSTM: breve repaso](#scrollTo=RemDAOPx5auE&line=1&uniqifier=1)\n",
        "2. [Keras y la celda LSTM básica](#scrollTo=CnqQ4VlH_WoL&line=10&uniqifier=1)\n",
        "3. [La opción \"return_sequences\"](#scrollTo=3hMNGse7BFKn&line=19&uniqifier=1)\n",
        "4. [La opción \"return_state\"](#scrollTo=J6fhsNIiE4jF&line=14&uniqifier=1)\n",
        "5. [Usando \"return_sequences\" y \"return_states\" simultáneamente](#scrollTo=3DSMNdaOJKXr&line=1&uniqifier=1)\n",
        "6. [Celda LSTM + capa \"Dense\"](#scrollTo=-ktFF1d-4ldC&line=9&uniqifier=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RemDAOPx5auE"
      },
      "source": [
        "## 1. Redes LSTM: breve repaso\n",
        "\n",
        "La Red LSTM tiene dos elementos centrales:\n",
        "\n",
        "- El estado oculto, que es como la **memoria de corto plazo** y\n",
        "- La celda de estado, que es como la **memoria de largo plazo**\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1D-KyGNut7oVSMgQChiIRiJ1uLSih4omw)\n",
        "\n",
        "Así que durante el entrenamiento la Red LSTM aprende a determinar qué información de corto y largo plazo es relevante para interpretar correctamente la secuencia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnqQ4VlH_WoL"
      },
      "source": [
        "## 2. Keras y la celda LSTM básica\n",
        "\n",
        "En Keras una Red LSTM básica se conoce como una celda.\n",
        "\n",
        "En su versión por defecto la creamos definiendo dos parámetros:\n",
        "\n",
        "- `input_shape`: el tamaño de cada dato de entrada (*timesteps* x *features*)\n",
        "- `units`: el número de unidades de la celda. Este número de unidades definirá a su vez la complejidad (número de parámetros) de la celda así como el tamaño del dato de salida (*units*)\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1Ej1XGizCIGIkzvebVW1S1thNVeA5H03B)\n",
        "\n",
        "\n",
        "Veamos un ejemplo sencillo. Creemos una celda LSTM con estas características:\n",
        "\n",
        "- Entradas: secuencias de 3 elementos y 1 feature (`input_shape` de 3x1)\n",
        "- Unidades: 5 (`units`)\n",
        "\n",
        "Veamos cómo implementar esta celda:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "3PVpIX8M3G-m",
        "outputId": "3f6951bf-b702-44d4-d16d-f5da78bc551b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\MaoYeral\\miniconda3\\envs\\ML_2\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\MaoYeral\\miniconda3\\envs\\ML_2\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "Información general del modelo: \n",
            "----------------------------------------------------------------------\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 3, 1)]            0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 5)                 140       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 140 (560.00 Byte)\n",
            "Trainable params: 140 (560.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "----------------------------------------------------------------------\n",
            "Tamaño entrada:  (None, 3, 1)\n",
            "Tamaño de salida: (None, 5)\n",
            "----------------------------------------------------------------------\n",
            "Predicción (h_t):  [[ 0.04174358 -0.06729254  0.03022056 -0.05514956  0.02848158]]\n",
            "Tamaño predicción:  (1, 5)\n"
          ]
        }
      ],
      "source": [
        "# Importar modulos requeridos\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM\n",
        "from tensorflow.random import set_seed\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Función fijar semillas (para reproducibilidad de los resultados)\n",
        "def fijar_semillas():\n",
        "    set_seed(123)\n",
        "    np.random.seed(123)\n",
        "    random.seed(123)\n",
        "\n",
        "# Crear celda LSTM:\n",
        "# - input_shape de 3x1\n",
        "# - units = 5\n",
        "fijar_semillas()\n",
        "entrada = Input(shape=(3,1)) # (timesteps = 3) x (features = 1)\n",
        "lstm_out = LSTM(5)(entrada) # Celda LSTM con 5 unidades\n",
        "modelo = Model(inputs=entrada, outputs=lstm_out)\n",
        "\n",
        "# Imprimir información del modelo\n",
        "print('Información general del modelo: ')\n",
        "print('-'*70)\n",
        "print(modelo.summary())\n",
        "\n",
        "print('-'*70)\n",
        "print('Tamaño entrada: ', modelo.input_shape)\n",
        "print('Tamaño de salida:', modelo.output_shape)\n",
        "\n",
        "# Generar predicción e imprimir resultado en pantalla\n",
        "datos = np.array([0.5, 0.4, 0.3]).reshape((1,3,1)) # 1 dato con 3 timesteps y 1 feature\n",
        "pred = modelo.predict(datos, verbose=0)\n",
        "\n",
        "print('-'*70)\n",
        "print('Predicción (h_t): ', pred)\n",
        "print('Tamaño predicción: ', pred.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLgNw0viAwRi"
      },
      "source": [
        "Vemos que la predicción (salida del modelo) tiene exactamente 5 elementos, el mismo número de unidades de la celda LSTM.\n",
        "\n",
        "Si ahora la entrada contiene 2 y no 1 *feature*, la salida seguirá teniendo 5 elementos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "Mp_kMP3x33_P",
        "outputId": "1e8b2837-50f5-42bb-f108-9d1577c3af13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Información general del modelo: \n",
            "----------------------------------------------------------------------\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 3, 2)]            0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 5)                 160       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160 (640.00 Byte)\n",
            "Trainable params: 160 (640.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "----------------------------------------------------------------------\n",
            "Tamaño entrada:  (None, 3, 2)\n",
            "Tamaño de salida: (None, 5)\n",
            "----------------------------------------------------------------------\n",
            "Predicción (h_t):  [[-0.09150496  0.05164479  0.19230194  0.07269354 -0.10549308]]\n",
            "Tamaño predicción:  (1, 5)\n"
          ]
        }
      ],
      "source": [
        "# Crear celda LSTM\n",
        "# - input_shape = 3 (timesteps) x 2 (features)\n",
        "# - units = 5\n",
        "fijar_semillas()\n",
        "entrada = Input(shape=(3,2))\n",
        "lstm_out = LSTM(5)(entrada)\n",
        "modelo = Model(inputs=entrada, outputs=lstm_out)\n",
        "\n",
        "# Imprimir información del modelo\n",
        "print('Información general del modelo: ')\n",
        "print('-'*70)\n",
        "print(modelo.summary())\n",
        "\n",
        "print('-'*70)\n",
        "print('Tamaño entrada: ', modelo.input_shape)\n",
        "print('Tamaño de salida:', modelo.output_shape)\n",
        "\n",
        "# Generar predicción e imprimir resultado en pantalla\n",
        "datos = np.array([[0.5, 0.4, 0.3],\n",
        "                  [0.6, 0.9, 0.8]]).reshape((1,3,2))\n",
        "pred = modelo.predict(datos, verbose=0)\n",
        "\n",
        "print('-'*70)\n",
        "print('Predicción (h_t): ', pred)\n",
        "print('Tamaño predicción: ', pred.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hMNGse7BFKn"
      },
      "source": [
        "## 3. La opción `return_sequences`\n",
        "\n",
        "En los ejemplos anteriores hemos usado las opciones por defecto.\n",
        "\n",
        "En particular, una de esas opciones por defecto es `return_sequences = False`.\n",
        "\n",
        "Con esta opción la salida de la celda únicamente contendrá la predicción correspondiente **último dato en la secuencia de entrada**:\n",
        "\n",
        "| *timestep* (entrada) | valor | salida ($h_t$)                   |\n",
        "|:--------------------:|:-----:|----------------------------------|\n",
        "| 1                    | 0.5   | -------------                              |\n",
        "| 2                    | 0.4   | -------------                              |\n",
        "| 3                    | 0.3   | [0.04, -0.06, 0.03, -0.05, 0.02] |\n",
        "\n",
        "\n",
        "Sin embargo, si hacemos `return_sequences=True` la celda retornará una predicción **por cada elemento en la secuencia de entrada**:\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1H2sadt1RT46C2hJvdxvh6YloqCwMklsd)\n",
        "\n",
        "\n",
        "Es decir que ahora la salida será de tamaño *timesteps* (el tamaño de la secuencia de entrada) x *units* (el número de unidades de la celda LSTM).\n",
        "\n",
        "Veamos el mismo caso del primer ejemplo (entrada de 3x1) pero ahora con `return_sequences=True`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "fUOAjbBK4j8y",
        "outputId": "1b9925d6-c1f6-45e2-d0a2-3a1478822fb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Información general del modelo: \n",
            "----------------------------------------------------------------------\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 3, 1)]            0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 3, 5)              140       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 140 (560.00 Byte)\n",
            "Trainable params: 140 (560.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "----------------------------------------------------------------------\n",
            "Tamaño entrada:  (None, 3, 1)\n",
            "Tamaño de salida: (None, 3, 5)\n",
            "----------------------------------------------------------------------\n",
            "Predicción (h_t):  [[[ 0.02129798 -0.04037673  0.02123253 -0.02901676  0.01275784]\n",
            "  [ 0.03483645 -0.0609595   0.02958979 -0.04655094  0.02243249]\n",
            "  [ 0.04174358 -0.06729254  0.03022056 -0.05514956  0.02848158]]]\n",
            "Tamaño predicción:  (1, 3, 5)\n"
          ]
        }
      ],
      "source": [
        "# Crear celda LSTM\n",
        "# - input_shape = 3x1\n",
        "# - units = 5\n",
        "# - return_sequences = True\n",
        "fijar_semillas()\n",
        "entrada = Input(shape=(3,1))\n",
        "lstm_out = LSTM(5,\n",
        "                return_sequences=True)(entrada) # *** Celda LSTM con return_sequences=True\n",
        "modelo = Model(inputs=entrada, outputs=lstm_out)\n",
        "\n",
        "# Imprimir información del modelo\n",
        "print('Información general del modelo: ')\n",
        "print('-'*70)\n",
        "print(modelo.summary())\n",
        "\n",
        "print('-'*70)\n",
        "print('Tamaño entrada: ', modelo.input_shape)\n",
        "print('Tamaño de salida:', modelo.output_shape)\n",
        "\n",
        "# Generar predicción e imprimir resultado en pantalla\n",
        "datos = np.array([0.5, 0.4, 0.3]).reshape((1,3,1))\n",
        "pred = modelo.predict(datos, verbose=0)\n",
        "\n",
        "print('-'*70)\n",
        "print('Predicción (h_t): ', pred)\n",
        "print('Tamaño predicción: ', pred.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewA8c-fYER9i"
      },
      "source": [
        "Así que veamos la diferencia entre `return_sequences=False` y `return_sequences=True`:\n",
        "\n",
        "| *timestep* (entrada) | valor | salida ($h_t$) sin \"return_sequences\" | salida ($h_t$) con \"return_sequences\" |\n",
        "|:--------------------:|:-----:|---------------------------------------|---------------------------------------|\n",
        "| 1                    | 0.5   | -------------                                   | [0.02, -0.04, 0.02, -0.02, 0.01]      |\n",
        "| 2                    | 0.4   | -------------                                   | [0.03, -0.06, 0.02, -0.04, 0.02]      |\n",
        "| 3                    | 0.3   | [0.04, -0.06, 0.03, -0.05, 0.02]      | [0.04, -0.06, 0.03, -0.05, 0.02]      |\n",
        "\n",
        "Es decir que:\n",
        "\n",
        "> `return_sequences=True` retorna **todos** los estados ocultos\n",
        "\n",
        "Esta opción de `return_sequences=True` la podemos usar por ejemplo cuando queremos usar múltiples celdas LSTM (es decir conectar una después de la otra)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6fhsNIiE4jF"
      },
      "source": [
        "## 4. La opción `return_state`\n",
        "\n",
        "Hasta este punto hemos visto que la Red LSTM únicamente retorna el estado oculto ($h_t$) pero no la celda de estado ($c_t$).\n",
        "\n",
        "Si queremos retornar el último estado oculto y el último valor de la celda de estado, debemos usar `return_states=True`:\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1GpgZjw78ykBE2UT3FEUYiYaKTpOH0HAy)\n",
        "\n",
        "En este caso la celda retorna 2 salidas:\n",
        "\n",
        "- El último estado oculto $h_t$\n",
        "- El último valor en la celda de estado $c_t$\n",
        "\n",
        "Por ejemplo, creemos la misma celda LSTM del primer ejemplo (entrada 3x1, 5 unidades) pero ahora usemos `return_state=True`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "g2O0n-lrHB7U",
        "outputId": "533889db-f26a-4d88-a7b8-e0df90071f0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Información general del modelo: \n",
            "----------------------------------------------------------------------\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 3, 1)]            0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               [(None, 5),               140       \n",
            "                              (None, 5),                         \n",
            "                              (None, 5)]                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 140 (560.00 Byte)\n",
            "Trainable params: 140 (560.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "----------------------------------------------------------------------\n",
            "Tamaño entrada:  (None, 3, 1)\n",
            "Tamaño de salida: [(None, 5), (None, 5), (None, 5)]\n",
            "----------------------------------------------------------------------\n",
            "Predicción (lstm_out):  [[ 0.04174358 -0.06729254  0.03022056 -0.05514956  0.02848158]]\n",
            "Tamaño predicción \"lstm_out\":  (1, 5)\n",
            "..................................................\n",
            "Predicción (h_t):  [[ 0.04174358 -0.06729254  0.03022056 -0.05514956  0.02848158]]\n",
            "Tamaño predicción \"h_t\":  (1, 5)\n",
            "..................................................\n",
            "Predicción (c_t):  [[ 0.08437636 -0.12790795  0.05566084 -0.11978056  0.05761085]]\n",
            "Tamaño predicción \"c_t\":  (1, 5)\n"
          ]
        }
      ],
      "source": [
        "# Crear celda LSTM\n",
        "# - input_shape = 3x1\n",
        "# - units = 5\n",
        "# - return_state = True\n",
        "fijar_semillas()\n",
        "entrada = Input(shape=(3,1)) # (timesteps = 3) x (features = 1)\n",
        "lstm_out, h_t, c_t = LSTM(5,\n",
        "                          return_state=True)(entrada) # ***Celda LSTM con return_state=True***\n",
        "modelo = Model(inputs=entrada, outputs=[lstm_out, h_t, c_t])\n",
        "\n",
        "# Imprimir información del modelo\n",
        "print('Información general del modelo: ')\n",
        "print('-'*70)\n",
        "print(modelo.summary())\n",
        "\n",
        "print('-'*70)\n",
        "print('Tamaño entrada: ', modelo.input_shape)\n",
        "print('Tamaño de salida:', modelo.output_shape)\n",
        "\n",
        "# Generar predicción e imprimir resultado en pantalla\n",
        "datos = np.array([0.5, 0.4, 0.3]).reshape((1,3,1))\n",
        "pred, h, c = modelo.predict(datos, verbose=0)\n",
        "\n",
        "print('-'*70)\n",
        "print('Predicción (lstm_out): ', pred)\n",
        "print('Tamaño predicción \"lstm_out\": ', pred.shape)\n",
        "print('.'*50)\n",
        "print('Predicción (h_t): ', h)\n",
        "print('Tamaño predicción \"h_t\": ', h.shape)\n",
        "print('.'*50)\n",
        "print('Predicción (c_t): ', c)\n",
        "print('Tamaño predicción \"c_t\": ', c.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Evul8UjJCyS"
      },
      "source": [
        "Es decir que en este caso tendremos:\n",
        "\n",
        "| *timestep* (entrada) | valor | $h_t$ | $c_t$ |\n",
        "|:--------------------:|:-----:|---------------------------------------|---------------------------------------|\n",
        "| 1                    | 0.5   | -------------                                   | -------------      |\n",
        "| 2                    | 0.4   | -------------                                   | -------------      |\n",
        "| 3                    | 0.3   | [0.04, -0.06, 0.03, -0.05, 0.02]      | [0.08, -0.12, 0.05, -0.11, 0.05]      |\n",
        "\n",
        "Esta opción es útil cuando procesamos secuencias relativamente largas y queremos preservar la memoria de largo plazo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DSMNdaOJKXr"
      },
      "source": [
        "## 5. Usando `return_sequences` y `return_state` simultáneamente\n",
        "\n",
        "Y finalmente podemos combinar `return_sequences=True` y `return_state=True` para retornar:\n",
        "\n",
        "- **Todos** los valores de la salida\n",
        "- El **último** estado oculto ($h_t$)\n",
        "- El **último** valor de la celda de estados ($c_t$):\n",
        "\n",
        "Veamos esta implementación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "RTzlsJfl8kbR",
        "outputId": "4dcda616-9bf9-4ecf-eb98-dcb5977ac294"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Información general del modelo: \n",
            "----------------------------------------------------------------------\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 3, 1)]            0         \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               [(None, 3, 5),            140       \n",
            "                              (None, 5),                         \n",
            "                              (None, 5)]                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 140 (560.00 Byte)\n",
            "Trainable params: 140 (560.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "----------------------------------------------------------------------\n",
            "Tamaño entrada:  (None, 3, 1)\n",
            "Tamaño de salida: [(None, 3, 5), (None, 5), (None, 5)]\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000018DCFD3BF40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "----------------------------------------------------------------------\n",
            "Predicción (lstm_out):  [[[ 0.02129798 -0.04037673  0.02123253 -0.02901676  0.01275784]\n",
            "  [ 0.03483645 -0.0609595   0.02958979 -0.04655094  0.02243249]\n",
            "  [ 0.04174358 -0.06729254  0.03022056 -0.05514956  0.02848158]]]\n",
            "Tamaño predicción \"lstm_out\":  (1, 3, 5)\n",
            "..................................................\n",
            "Último estado oculto (h_t):  [[ 0.04174358 -0.06729254  0.03022056 -0.05514956  0.02848158]]\n",
            "Tamaño último estado oculto \"h_t\":  (1, 5)\n",
            "..................................................\n",
            "Último valor celda de estado (c_t):  [[ 0.08437636 -0.12790795  0.05566084 -0.11978056  0.05761085]]\n",
            "Tamaño último valor celda de estado \"c_t\":  (1, 5)\n"
          ]
        }
      ],
      "source": [
        "# Crear celda LSTM\n",
        "# - input_shape = 3x1\n",
        "# - units = 5\n",
        "# - return_sequences = True\n",
        "# - return_states = True\n",
        "fijar_semillas()\n",
        "entrada = Input(shape=(3,1))\n",
        "lstm_out, h, c = LSTM(5,\n",
        "                      return_sequences=True,\n",
        "                      return_state=True)(entrada) # Celda LSTM\n",
        "modelo = Model(inputs=entrada, outputs=[lstm_out, h, c])\n",
        "\n",
        "# Imprimir información del modelo\n",
        "print('Información general del modelo: ')\n",
        "print('-'*70)\n",
        "print(modelo.summary())\n",
        "\n",
        "print('-'*70)\n",
        "print('Tamaño entrada: ', modelo.input_shape)\n",
        "print('Tamaño de salida:', modelo.output_shape)\n",
        "\n",
        "# Generar predicción e imprimir resultado en pantalla\n",
        "datos = np.array([0.5, 0.4, 0.3]).reshape((1,3,1))\n",
        "pred, h, c = modelo.predict(datos, verbose=0)\n",
        "\n",
        "print('-'*70)\n",
        "print('Predicción (lstm_out): ', pred)\n",
        "print('Tamaño predicción \"lstm_out\": ', pred.shape)\n",
        "print('.'*50)\n",
        "print('Último estado oculto (h_t): ', h)\n",
        "print('Tamaño último estado oculto \"h_t\": ', h.shape)\n",
        "print('.'*50)\n",
        "print('Último valor celda de estado (c_t): ', c)\n",
        "print('Tamaño último valor celda de estado \"c_t\": ', c.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ktFF1d-4ldC"
      },
      "source": [
        "## 6. Celda LSTM + capa \"Dense\"\n",
        "\n",
        "Cuando queremos por ejemplo generar pronósticos sobre Series de Tiempo o clasificar una secuencia (por ejemplo en análisis de sentimientos) debemos añadir una capa de salida a la celda LSTM:\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1HCNWkAmn_o9QEv_IIzWpeSRs7oIbAYHm)\n",
        "\n",
        "Por ejemplo, si queremos generar pronósticos o generar texto a la salida, la capa `Dense` debe hacer una tarea de regresión (es decir debe predecir un número). En este caso la función de activación de `Dense` debe ser lineal.\n",
        "\n",
        "Por ejemplo, este sería el código para predecir un valor a futuro:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "PSxe_Kkw9wz-",
        "outputId": "7ef6aa42-db9e-4b36-b41d-b5d57a66023e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Información general del modelo: \n",
            "----------------------------------------------------------------------\n",
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 3, 1)]            0         \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 5)                 140       \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 146 (584.00 Byte)\n",
            "Trainable params: 146 (584.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "----------------------------------------------------------------------\n",
            "Tamaño entrada:  (None, 3, 1)\n",
            "Tamaño de salida: (None, 1)\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000018DD0FE8B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "----------------------------------------------------------------------\n",
            "Predicción (regresión):  [[-0.06192685]]\n",
            "Tamaño predicción:  (1, 1)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Crear celda LSTM:\n",
        "# - input_shape de 3x1\n",
        "# - units = 5\n",
        "fijar_semillas()\n",
        "entrada = Input(shape=(3,1)) # (timesteps = 3) x (features = 1)\n",
        "lstm_out = LSTM(5)(entrada) # Celda LSTM con 5 unidades\n",
        "\n",
        "# Agregar capa de salida Dense\n",
        "salida = Dense(1)(lstm_out) # Capa de salida con 1 neurona y función de activación lineal\n",
        "modelo = Model(inputs=entrada, outputs=salida)\n",
        "\n",
        "# Imprimir información del modelo\n",
        "print('Información general del modelo: ')\n",
        "print('-'*70)\n",
        "print(modelo.summary())\n",
        "\n",
        "print('-'*70)\n",
        "print('Tamaño entrada: ', modelo.input_shape)\n",
        "print('Tamaño de salida:', modelo.output_shape)\n",
        "\n",
        "# Generar predicción e imprimir resultado en pantalla\n",
        "datos = np.array([0.5, 0.4, 0.3]).reshape((1,3,1)) # 1 dato con 3 timesteps y 1 feature\n",
        "pred = modelo.predict(datos, verbose=0)\n",
        "\n",
        "print('-'*70)\n",
        "print('Predicción (regresión): ', pred)\n",
        "print('Tamaño predicción: ', pred.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNXhrvBI-MuQ"
      },
      "source": [
        "Y si queremos predecir múltiples valores simplemente añadimos el número de neuronas requerido a la capa \"Dense\".\n",
        "\n",
        "Por ejemplo, este sería el código para predecir 2 valores a futuro:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "UXCPDs3x-X8X",
        "outputId": "3dbbab76-1039-44e7-9a26-5a6209a46b22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Información general del modelo: \n",
            "----------------------------------------------------------------------\n",
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 3, 1)]            0         \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 5)                 140       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 12        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 152 (608.00 Byte)\n",
            "Trainable params: 152 (608.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "----------------------------------------------------------------------\n",
            "Tamaño entrada:  (None, 3, 1)\n",
            "Tamaño de salida: (None, 2)\n",
            "----------------------------------------------------------------------\n",
            "Predicción (regresión):  [[0.01347888 0.0076959 ]]\n",
            "Tamaño predicción:  (1, 2)\n"
          ]
        }
      ],
      "source": [
        "# Crear celda LSTM:\n",
        "# - input_shape de 3x1\n",
        "# - units = 5\n",
        "fijar_semillas()\n",
        "entrada = Input(shape=(3,1)) # (timesteps = 3) x (features = 1)\n",
        "lstm_out = LSTM(5)(entrada) # Celda LSTM con 5 unidades\n",
        "\n",
        "\n",
        "# Agregar capa de salida Dense\n",
        "salida = Dense(2)(lstm_out) # Capa de salida con 2 neuronas y función de activación lineal\n",
        "modelo = Model(inputs=entrada, outputs=salida)\n",
        "\n",
        "# Imprimir información del modelo\n",
        "print('Información general del modelo: ')\n",
        "print('-'*70)\n",
        "print(modelo.summary())\n",
        "\n",
        "print('-'*70)\n",
        "print('Tamaño entrada: ', modelo.input_shape)\n",
        "print('Tamaño de salida:', modelo.output_shape)\n",
        "\n",
        "# Generar predicción e imprimir resultado en pantalla\n",
        "datos = np.array([0.5, 0.4, 0.3]).reshape((1,3,1)) # 1 dato con 3 timesteps y 1 feature\n",
        "pred = modelo.predict(datos, verbose=0)\n",
        "\n",
        "print('-'*70)\n",
        "print('Predicción (regresión): ', pred)\n",
        "print('Tamaño predicción: ', pred.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPxSkYFK-cof"
      },
      "source": [
        "Si queremos predecir una categoría podemos usar \"Dense\" pero con función de activación \"sigmoid\" (para máximo 2 categorías) o función de activación \"softmax\" (para 3 o más categorías).\n",
        "\n",
        "Por ejemplo, un clasificador de secuencias binario sería similar a este:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "RNExzmsh-oUH",
        "outputId": "9dc4aa49-7336-46a2-d074-c590c3bde426"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Información general del modelo: \n",
            "----------------------------------------------------------------------\n",
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 3, 1)]            0         \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 5)                 140       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 146 (584.00 Byte)\n",
            "Trainable params: 146 (584.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "----------------------------------------------------------------------\n",
            "Tamaño entrada:  (None, 3, 1)\n",
            "Tamaño de salida: (None, 1)\n",
            "----------------------------------------------------------------------\n",
            "Predicción (clasificación binaria):  [[0.48452324]]\n",
            "Tamaño predicción:  (1, 1)\n"
          ]
        }
      ],
      "source": [
        "# Crear celda LSTM:\n",
        "# - input_shape de 3x1\n",
        "# - units = 5\n",
        "fijar_semillas()\n",
        "entrada = Input(shape=(3,1)) # (timesteps = 3) x (features = 1)\n",
        "lstm_out = LSTM(5)(entrada) # Celda LSTM con 5 unidades\n",
        "\n",
        "# Agregar capa de salida Dense para clasificación\n",
        "salida = Dense(1, activation='sigmoid')(lstm_out) # Capa de salida con 2 neuronas y función de activación sigmoidal\n",
        "modelo = Model(inputs=entrada, outputs=salida)\n",
        "\n",
        "# Imprimir información del modelo\n",
        "print('Información general del modelo: ')\n",
        "print('-'*70)\n",
        "print(modelo.summary())\n",
        "\n",
        "print('-'*70)\n",
        "print('Tamaño entrada: ', modelo.input_shape)\n",
        "print('Tamaño de salida:', modelo.output_shape)\n",
        "\n",
        "# Generar predicción e imprimir resultado en pantalla\n",
        "datos = np.array([0.5, 0.4, 0.3]).reshape((1,3,1)) # 1 dato con 3 timesteps y 1 feature\n",
        "pred = modelo.predict(datos, verbose=0)\n",
        "\n",
        "print('-'*70)\n",
        "print('Predicción (clasificación binaria): ', pred)\n",
        "print('Tamaño predicción: ', pred.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHJL5Gdk-2_J"
      },
      "source": [
        "Y este sería el código de ejemplo para un clasificador de secuencias con 4 categorías:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "zJLdmwUF-83-",
        "outputId": "45466a56-5e75-4840-85c3-2c7f41199db3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Información general del modelo: \n",
            "----------------------------------------------------------------------\n",
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 3, 1)]            0         \n",
            "                                                                 \n",
            " lstm_8 (LSTM)               (None, 5)                 140       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 164 (656.00 Byte)\n",
            "Trainable params: 164 (656.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "----------------------------------------------------------------------\n",
            "Tamaño entrada:  (None, 3, 1)\n",
            "Tamaño de salida: (None, 4)\n",
            "----------------------------------------------------------------------\n",
            "Predicción (clasificación multiclase):  [[0.26582992 0.25042662 0.22758333 0.25616005]]\n",
            "Tamaño predicción:  (1, 4)\n"
          ]
        }
      ],
      "source": [
        "# Crear celda LSTM:\n",
        "# - input_shape de 3x1\n",
        "# - units = 5\n",
        "fijar_semillas()\n",
        "entrada = Input(shape=(3,1)) # (timesteps = 3) x (features = 1)\n",
        "lstm_out = LSTM(5)(entrada) # Celda LSTM con 5 unidades\n",
        "\n",
        "# Agregar capa de salida Dense para clasificación\n",
        "salida = Dense(4, activation='softmax')(lstm_out) # Capa de salida con 2 neuronas y función de activación sigmoidal\n",
        "modelo = Model(inputs=entrada, outputs=salida)\n",
        "\n",
        "# Imprimir información del modelo\n",
        "print('Información general del modelo: ')\n",
        "print('-'*70)\n",
        "print(modelo.summary())\n",
        "\n",
        "print('-'*70)\n",
        "print('Tamaño entrada: ', modelo.input_shape)\n",
        "print('Tamaño de salida:', modelo.output_shape)\n",
        "\n",
        "# Generar predicción e imprimir resultado en pantalla\n",
        "datos = np.array([0.5, 0.4, 0.3]).reshape((1,3,1)) # 1 dato con 3 timesteps y 1 feature\n",
        "pred = modelo.predict(datos, verbose=0)\n",
        "\n",
        "print('-'*70)\n",
        "print('Predicción (clasificación multiclase): ', pred)\n",
        "print('Tamaño predicción: ', pred.shape)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ML_2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
