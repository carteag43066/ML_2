{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Presentación 5: Redes Neuronales\"\n",
        "subtitle: \"*Machine Learning II*\"\n",
        "author: \"Jose Alexander Fuentes Montoya Ph.D(c)\"\n",
        "format:\n",
        "  revealjs:\n",
        "    theme: \"moon\"\n",
        "    slideNumber: true\n",
        "    transition: \"convex\"            # Transición más dinámica\n",
        "    center: false\n",
        "    incremental: true\n",
        "    plugins: [\"notes\", \"highlight\", \"math\", \"search\", \"zoom\"]  # Plugins para interactividad\n",
        "    backgroundTransition: \"fade\"\n",
        "title-slide-attributes:\n",
        "  data-background-image: \"logo.png\"\n",
        "  data-background-size: \"10%\"\n",
        "  data-background-position: \"90% 10%\"\n",
        "---\n",
        "\n",
        "\n",
        "# Redes Neuronales\n",
        "\n",
        "# Visión general de la lección\n",
        "\n",
        "-  **Tensores en aprendizaje profundo**  \n",
        "-  **Tensores y PyTorch**  \n",
        "-  **Vectores, matrices y broadcasting**  \n",
        "-  **Convenciones de notación para redes neuronales**  \n",
        "-  **Capa totalmente conectada (lineal) en PyTorch**  \n",
        "\n",
        "\n",
        "# Tensores en aprendizaje profundo\n",
        "\n",
        "\n",
        "## Vectores, matrices y tensores — Convenciones de notación\n",
        "\n",
        "::: columns\n",
        "\n",
        "::: {.column width=\"33%\" style=\"font-size:0.6em\"}\n",
        "*Rango 0 y 1*\n",
        "\n",
        "**Escalar**  \n",
        "(rank‑0 tensor)  \n",
        "$$x \\in \\mathbb{R}$$ \n",
        "\n",
        "**Vector**  \n",
        "(rank‑1 tensor)  \n",
        "$$x \\in \\mathbb{R}^n,\\quad x\\in\\mathbb{R}^{n\\times1}$$  \n",
        "$$\n",
        "x = \\begin{bmatrix}\n",
        "x_1\\\\\n",
        "x_2\\\\\n",
        "\\vdots\\\\\n",
        "x_n\n",
        "\\end{bmatrix}\n",
        "$$ \n",
        "\n",
        ":::\n",
        "\n",
        "::: {.column width=\"33%\" style=\"font-size:0.5em\"}\n",
        "*Rango 2*\n",
        "\n",
        "**Matriz**  \n",
        "(rank‑2 tensor)  \n",
        "$$X \\in \\mathbb{R}^{m\\times n}$$  \n",
        "$$\n",
        "X = \\begin{bmatrix}\n",
        "x_{1,1} & x_{1,2} & \\dots  & x_{1,n} \\\\\n",
        "x_{2,1} & x_{2,2} & \\dots  & x_{2,n} \\\\\n",
        "\\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
        "x_{m,1} & x_{m,2} & \\dots  & x_{m,n}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        ":::\n",
        ":::::\n",
        "\n",
        "<div style=\"font-size:80%;\">\n",
        "\n",
        "## Vectores, matrices y tensores — Convenciones de notación\n",
        "\n",
        "$X$ para referirnos a la “matriz de diseño”. Es decir, la matriz que contiene los ejemplos de entrenamiento y las características (entradas).** \n",
        "\n",
        "**$$X \\in \\mathbb{R}^{n\\times m}$$** \n",
        "\n",
        "**Y asumiremos la siguiente estructura**  \n",
        "_(donde $n$ suele emplearse para referirse al número de ejemplos)_ \n",
        "\n",
        "$$\n",
        "X = \\begin{bmatrix}\n",
        "x^{(1)}_{1} & x^{(1)}_{2} & \\dots  & x^{(1)}_{m} \\\\[6pt]\n",
        "x^{(2)}_{1} & x^{(2)}_{2} & \\dots  & x^{(2)}_{m} \\\\[6pt]\n",
        "\\vdots      & \\vdots      & \\ddots & \\vdots      \\\\[6pt]\n",
        "x^{(n)}_{1} & x^{(n)}_{2} & \\dots  & x^{(n)}_{m}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "</div>\n",
        "\n",
        "## Tensor 3D\n",
        "\n",
        "**$X \\in \\mathbb{R}^{m\\times n\\times p}$** \n",
        "\n",
        "Se suele pensar como $p$ “rebanadas” de tamaño $m\\times n$:  \n",
        "\n",
        "![Figura 5-1. Tensor 3D](presentacion_files/41.png)\n",
        "\n",
        "## Tensor 3D imagen\n",
        "\n",
        "![Tensor 3D ](presentacion_files/42.png)\n",
        "\n",
        "- **Imagen de un solo canal**  \n",
        "- **Tensor 3D**: alto × ancho × canales  \n",
        "- Usado para almacenamiento de arreglos multidimensionales y cómputo paralelo  \n",
        "- Seguimos aplicando operaciones de vectores y matrices  \n",
        "\n",
        "<div style=\"font-size:70%;\">\n",
        "## Ejemplo tensor 4D\n",
        "\n",
        "![Lote de imágenes (CIFAR-10)](presentacion_files/43.png){width=\"150%\"}\n",
        "\n",
        "\n",
        "- **Tensor 4D**:  \n",
        "  `batch_size` × `alto` × `ancho` × `canales`\n",
        "\n",
        "- Uso: almacenamiento de arreglos multidimensionales  \n",
        "  y cómputo paralelo, aplicando operaciones de vectores  \n",
        "  y matrices de manera eficiente.\n",
        "\n",
        "</div>\n",
        "\n",
        "## En el contexto de TensorFlow, NumPy y PyTorch\n",
        "\n",
        "-  **Tensores = arreglos multidimensionales**\n",
        "-  **La dimensionalidad coincide con el número de índices de** `.shape`\n"
      ],
      "id": "22f71897"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "id": "fcbdf4d8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. tanh\n",
        "\n",
        "::::: {.columns style=\"font-size:80%;\"}\n",
        "::: {.column width=\"40%\"}\n",
        "![Figura 3-9. Función tanh](presentacion_files/27.png)\n",
        ":::\n",
        "\n",
        "::: {.column width=\"60%\"}\n",
        "\n",
        "**Definición**\\\n",
        "$$ f(x) = \\frac{e^x - e^{-x}}{\\,e^x + e^{-x}\\,} $$\n",
        "\n",
        "-   Rango ((-1,1)).\\\n",
        "-   *Zero-centered*.\\\n",
        "-   También padece *vanishing gradient*.\n",
        "\n",
        "**Nota de importancia**\\\n",
        "La función *tanh* se introdujo como **alternativa a la Sigmoide** para que la salida se centre en torno a 0, lo cual en muchos casos facilita el entrenamiento y la convergencia.\n",
        ":::\n",
        ":::::\n",
        "\n",
        "## 3. ReLU (Rectified Linear Unit)\n",
        "\n",
        "::::: {.columns style=\"font-size:80%;\"}\n",
        "::: {.column width=\"60%\"}\n",
        "**Definición**\\\n",
        "$$ f(x) = \\max(0, x) $$\n",
        "\n",
        "-   Eficiente, con salida en $[0,\\infty)$.\\\n",
        "-   Minimiza *vanishing gradient*.\\\n",
        "-   Problema: si (x\\<0), salida = 0 ⇒ “neurona muerta”; no está acotada arriba ⇒ posible *exploding gradient*.\n",
        "\n",
        "**Nota de importancia**\\\n",
        "La ReLU revolucionó el **entrenamiento de redes profundas** por su bajo costo computacional y su efectividad en la región positiva.\n",
        ":::\n",
        "\n",
        "::: {.column width=\"40%\"}\n",
        "![Figura 3-10. Función ReLU](presentacion_files/28.png)\n",
        ":::\n",
        ":::::\n",
        "\n",
        "## 4. Leaky ReLU\n",
        "\n",
        "::::: {.columns style=\"font-size:80%;\"}\n",
        "::: {.column width=\"40%\"}\n",
        "**Definición**\\\n",
        "$$ f(x) = \n",
        "  \\begin{cases} \n",
        "    x, & x \\ge 0 \\\\ \n",
        "    \\alpha x, & x < 0 \n",
        "  \\end{cases}$$\n",
        "\n",
        "-   Evita el problema de neuronas muertas (al permitir un gradiente distinto de 0 en la región negativa).\\\n",
        "-   Mantiene un gradiente continuo para $x < 0$.\n",
        ":::\n",
        "\n",
        "::: {.column width=\"60%\"}\n",
        "-   Pierde parte de la “sparsidad” (pues ya no pone en cero todos los valores negativos).\n",
        "\n",
        "    **Nota de importancia**\\\n",
        "    La Leaky ReLU se creó para **abordar la desventaja** de la ReLU pura. Al permitir una pequeña pendiente $\\alpha$ en el dominio negativo, ayuda a reducir la posibilidad de neuronas muertas.\n",
        ":::\n",
        ":::::\n",
        "\n",
        "<div style=\"font-size:65%;\">\n",
        "\n",
        "## Tabla Comparativa de Funciones de Activación\n",
        "\n",
        "| Función        | Ecuación                                                               | Rango       | Ventajas / Desventajas                                                                                     |\n",
        "|----------------|------------------------------------------------------------------------|-------------|-------------------------------------------------------------------------------------------------------------|\n",
        "| **Sigmoide**   | $f(x) = \\frac{1}{1 + e^{-x}}$                                          | (0, 1)      | Interpretación probabilística; sufre saturación y vanishing gradient.                                       |\n",
        "| **tanh**       | $f(x) = \\tanh(x)$                                                      | (-1, 1)     | Zero-centered; parecido a sigmoide, pero también saturable.                                                 |\n",
        "| **ReLU**       | $f(x) = \\max(0, x)$                                                    | [0, ∞)      | Eficiente, no satura en la región positiva; puede generar “neurona muerta”.                                 |\n",
        "| **Leaky ReLU** | $f(x) = \\begin{cases} x, & x \\ge 0 \\\\ \\alpha x, & x < 0 \\end{cases}$   | $\\mathbb{R}$ | Evita neuronas muertas; pierde parte de la “sparsidad”.                                                    |\n",
        "| **SoftPlus**   | $f(x) = \\ln(1 + e^x)$                                                  | (0, ∞)      | Versión “suave” de ReLU; no tiene discontinuidad en $x=0$; puede saturarse para valores muy negativos.      |\n",
        "| **GELU**       | $f(x) = x \\,\\Phi(x)$, donde $\\Phi$ es la CDF de la Normal estándar      | $\\mathbb{R}$ | Similar a ReLU, pero introduce un componente probabilístico; transición más suave alrededor de $x=0$.      |\n",
        "\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "> [**Ver código en GoogleColab Funciones de activación**](https://colab.research.google.com/drive/1hLj81KfVSG-yfRn1hxEFgq2dmJoFJtTQ?authuser=1#scrollTo=7596195b-efaa-4ca3-99aa-cd81339012b3)\n",
        "\n",
        "# Funciones de Salida: Softmax\n",
        "\n",
        "## Funciones de Salida para Clasificación Multiclase\n",
        "\n",
        "::::: {.columns style=\"font-size:75%;\"}\n",
        "::: {.column width=\"60%\"}\n",
        "-   **Uso principal:** Clasificación multiclase (K clases).\\\n",
        "\n",
        "-   **Definición:** $$\n",
        "    \\text{softmax}(s_i) = \\frac{e^{s_i}}{\\sum_{j=1}^{K} e^{s_j}}\n",
        "    $$\n",
        "\n",
        "-   **Interpretación:**\n",
        "\n",
        "    -   Transforma un vector de puntajes $(s_1, s_2, \\ldots, s_K)$ en probabilidades que **suman 1**.\\\n",
        "    -   Resalta la clase de mayor puntaje y “suprime” las restantes, haciendo que una de las probabilidades destaque.\n",
        ":::\n",
        "\n",
        "::: {.column width=\"40%\"}\n",
        "![Figura 4.7. Comparación de salidas crudas vs. softmax](presentacion_files/34.png) **Adicional**\\\n",
        "Las probabilidades suman 1 para que haya una distribución de probabilidad coherente sobre las $K$ clases posibles.\n",
        ":::\n",
        ":::::\n",
        "\n",
        "# Multi-layer Perceptron (MLP)\n",
        "\n",
        "El Multi-layer Perceptron crea efectivamente una representación de características jerárquica y puede manejar datos no linealmente separables. Empecemos resolviendo el problema XOR usando un MLP.\n",
        "\n",
        "## Resolviendo el Problema XOR (I)\n",
        "\n",
        "::::: {.columns style=\"font-size:75%;\"}\n",
        "::: {.column width=\"45%\"}\n",
        "Consideremos una compuerta XOR. Ya hemos visto que no puede implementarse con un SLP. También se puede crear una compuerta NAND de la misma manera que una compuerta AND con entradas negadas.\n",
        ":::\n",
        "\n",
        "::: {.column width=\"55%\"}\n",
        "![Figura 4.8. Placeholder: NAND y OR con SLP](presentacion_files/36.png) Ahora, consideremos una red con dos entradas $X_1$ y $X_2$. Es sencillo crear un SLP para la implementación de las compuertas NAND y OR, tal como se muestra en la Figura.\n",
        ":::\n",
        ":::::\n",
        "\n",
        "## Resolviendo el Problema XOR (II)\n",
        "\n",
        "::::: {.columns style=\"font-size:65%;\"}\n",
        "::: {.column width=\"45%\"}\n",
        "Para construir una compuerta XOR, la salida de las redes anteriores actúa como entrada para una neurona en la siguiente capa, la cual implementa la compuerta AND Figura.\n",
        "\n",
        "**Matemática de XOR**\n",
        "\n",
        "-   XOR puede representarse por la expresión booleana: $$\n",
        "      Y = AB' + A'B \n",
        "      $$\n",
        "\n",
        "-   **NAND** puede representarse como: $$\n",
        "      Y = (A \\cdot B)'\n",
        "      $$\n",
        "\n",
        "-   lo cual, aplicando la Ley de De Morgan, se escribe como: $$\n",
        "      Y = A' + B'\n",
        "      $$\n",
        ":::\n",
        "\n",
        "::: {.column width=\"55%\"}\n",
        "![Figura 4.9. Placeholder: XOR con NAND, OR y AND](presentacion_files/37.png)\n",
        "\n",
        "-   Ahora, multiplicando $A + B$ con $Y$, obtenemos: $$\n",
        "      Z = (A + B)(A' + B') = AA' + AB' + BA' + BB'\n",
        "      $$ $$\n",
        "      Z = AB' + A'B\n",
        "      $$ Por tanto, XOR puede verse como AND de NAND y OR.\n",
        ":::\n",
        ":::::\n",
        "\n",
        "## Arquitectura de MLP y Forward Pass (I)\n",
        "\n",
        "::::: {.columns style=\"font-size:70%;\"}\n",
        "::: {.column width=\"45%\"}\n",
        "**Architecture of MLP and Forward Pass**\\\n",
        "Un Multi-layer Perceptron tiene una capa de entrada, una de salida y al menos una capa oculta.\n",
        "\n",
        "**Cálculo en la capa oculta**\\\n",
        "Sea $X_1, X_2, \\dots, X_n$ la entrada y $W_{ij}$ los pesos entre la primera y la segunda capa. Para la neurona $p$ en la capa oculta:\n",
        "\n",
        "$$\n",
        "U_p = \\sum_i X_i \\,W_{ip} + b_p\n",
        "$$\n",
        "\n",
        "La salida de esa neurona: $$\n",
        "V_p = f(U_p)\n",
        "$$\n",
        ":::\n",
        "\n",
        "::: {.column width=\"55%\"}\n",
        "![Figura 4.10. Placeholder: MLP con n entradas y 1 salida](presentacion_files/38.png)\n",
        ":::\n",
        ":::::\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## Arquitectura de MLP y Forward Pass\n",
        "\n",
        "**Cálculo en la capa de salida**\\\n",
        "Sea (q) la neurona en la capa de salida:\n",
        "\n",
        "$$\n",
        "U_q = \\sum_p V_p \\,W_{pq} + b_q\n",
        "$$\n",
        "\n",
        "$$\n",
        "V_q = f(U_q)\n",
        "$$\n",
        "\n",
        "En cada capa, calculamos la salida para usarla como entrada de la siguiente capa. Este tipo de red se denomina **Feed-Forward Network**.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "::::: {.columns style=\"font-size:70%;\"}\n",
        "::: {.column width=\"50%\"}\n",
        "**Como ejemplo**, consideremos la clasificación de un subconjunto del **IRIS dataset** (dos clases: Setosa y Versicolor, cuatro features). La red tiene cuatro neuronas de entrada, dos en la capa oculta y una en la de salida.\n",
        "\n",
        "-   **Forward Pass**\\\n",
        "    Se asume que los pesos y bias están inicializados. Para la primera capa oculta: ![Figura 4.10. Cálculos](presentacion_files/40.png) La salida de la neurona final: $$\n",
        "    O = f\\bigl(V_1 \\, w_{1}^2 + V_2 \\, w_{2}^2 + b\\bigl)\n",
        "    $$\n",
        ":::\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "![Figura 4.11. Placeholder: MLP con 4 entradas, 2 oculta, 1 salida](presentacion_files/39.png)\n",
        ":::\n",
        ":::::\n",
        "\n",
        "## Cálculo de la Salida (Ejemplo IRIS)\n",
        "\n",
        "**Comparación y Error**\\\n",
        "Una vez que se calcula la salida $O$, se compara con la salida deseada $\\hat{y}$ (o $y_i$, etc.). Por ejemplo, si usamos error cuadrático:\n",
        "\n",
        "$$\n",
        "L = \\frac{1}{2}(\\hat{y} - O)^2.\n",
        "$$\n",
        "\n",
        "**Idea:** Minimizar $L$. Para ello, es necesario ajustar los pesos mediante un método de optimización, típicamente **Gradiente Descendiente**.\n",
        "\n",
        "# Modularidad en un Sistema de Deep Learning\n",
        "\n",
        "Según la perspectiva presentada en el complemento, un sistema de deep learning se compone de:\n",
        "\n",
        "-   **Bloques de representación:** Secuencias de transformaciones lineales y no lineales que extraen características relevantes.\\\n",
        "-   **Clasificador lineal:** Una última capa que asigna la etiqueta de clase basándose en las representaciones aprendidas.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "![Figura 4.7. Sistema de Deep Learning](presentacion_files/33.png)\n",
        "\n",
        "> Los módulos se ensamblan en grafos y se optimizan mediante métodos basados en gradiente\n",
        "\n",
        "# Optimización: Propagación y Gradiente Descendente\n",
        "\n",
        "## Gradiente Descendiente\n",
        "\n",
        "::::: {.columns style=\"font-size:75%;\"}\n",
        "::: {.column width=\"60%\"}\n",
        "En un pipeline de Machine Learning, se suelen:\n",
        "\n",
        "1.  Preprocesar datos.\\\n",
        "2.  Extraer y seleccionar características.\\\n",
        "3.  Hacer predicciones con un modelo.\\\n",
        "4.  Diseñar una función de pérdida para medir la diferencia entre predicción y valor real.\n",
        ":::\n",
        "\n",
        "::: {.column width=\"40%\"}\n",
        "![Figura 4.7. gráfico en 3D ilustra cómo se va minimizando la función de pérdida a lo largo de dos parámetros](presentacion_files/35.png)\n",
        ":::\n",
        ":::::\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "El proceso de aprendizaje de una red neuronal se divide en dos fases:\n",
        "\n",
        "1.  **Forward Propagation:**\\\n",
        "    Se calculan las salidas pasando la entrada a través de todas las capas.\n",
        "\n",
        "2.  **Backward Propagation:**\\\n",
        "    Se calcula el gradiente del error para ajustar los parámetros mediante técnicas de optimización **gradiente descendente**.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "La regla de actualización de parámetros es:\n",
        "\n",
        "$$\n",
        "  \\theta := \\theta - \\eta\\, \\nabla_\\theta \\mathcal{L}(\\theta)\n",
        "  $$\n",
        "\n",
        "donde:\n",
        "\n",
        "-   $\\theta$ representa los parámetros (pesos y bias).\\\n",
        "-   $\\eta$ es la tasa de aprendizaje.\\\n",
        "-   $\\nabla_\\theta \\mathcal{L}(\\theta)$ es el gradiente del error.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "[**Consulta el notebook 03-Gradient_Descent.ipynb para un ejemplo interactivo.**](https://colab.research.google.com/drive/1qnfi3gbIPyBGRDmhpzVCHKgQA11zlqLw?authuser=1#scrollTo=_LGPUWenkH2A)\n",
        "\n",
        "## Descenso por Gradiente\n",
        "\n",
        "1.  **Valor predicho**\\\n",
        "    $$\n",
        "    \\hat{y} = f(\\mathbf{W}^T \\mathbf{X} + b)\n",
        "    $$\n",
        "\n",
        "2.  **Función de pérdida** (mitad del error cuadrático)\\\n",
        "    $$\n",
        "     \\frac{\\partial L}{\\partial \\mathbf{W}} = \\dfrac{\\partial\\bigl(1/2(\\hat{y}_i - y_i)^2\\bigr)}{\\partial \\mathbf{W}}\n",
        "    $$\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "3.  **Derivada de la pérdida respecto a (W)**\\\n",
        "    $$\n",
        "    \\frac{\\partial L}{\\partial \\mathbf{W}}=\n",
        "      \\dfrac{\\partial\\bigl(1/2(f(\\mathbf{W}^T \\mathbf{X} + b) - y_i)^2\\bigr)}{\\partial \\mathbf{W}}\n",
        "    $$\n",
        "\n",
        "4.  **Derivada de la pérdida respecto a (b)**\\\n",
        "    $$\n",
        "    \\frac{\\partial L}{\\partial \\mathbf{W}}=\n",
        "      \\dfrac{\\bigl(f(\\mathbf{W}^T \\mathbf{X} + b) - y_i)\\bigr)\\times f(1-f)\\times \\mathbf{X} }{\\partial \\mathbf{W}}\n",
        "    $$\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "**Actualización de los pesos y bias**\\\n",
        "$$\n",
        "\\mathbf{W}_\\text{nuevo}\n",
        "=\n",
        "\\mathbf{W}_\\text{viejo}\n",
        "-\n",
        "\\alpha\n",
        "\\;\\frac{\\partial L}{\\partial \\mathbf{W}}\n",
        ",\\qquad \\\\\n",
        "b_\\text{nuevo}\n",
        "=\n",
        "b_\\text{viejo}\n",
        "-\n",
        "\\alpha (\\hat{y}_i - y_i)f(1-f).\n",
        "$$\n",
        "\n",
        "**Comentario:**\\\n",
        "- $\\alpha$ = tasa de aprendizaje\\\n",
        "- $\\mathbf{X}$ = vector de entrada\n",
        "\n",
        "\n",
        "## Backpropagation (I)\n",
        "\n",
        "::: {style=\"font-size:90%;\"}\n",
        "# Backpropagation y Ajuste de Pesos  \n",
        "\n",
        "En redes neuronales multicapa (MLP), el **backpropagation** es el método que ajusta los pesos en **todas** las capas, propagando el error desde la salida hasta la capa de entrada.\n",
        "\n",
        ":::\n",
        "\n",
        "## Explicación Conceptual de Backpropagation\n",
        "\n",
        "::: {style=\"font-size:80%;\"}\n",
        "**Backpropagation** es el proceso para actualizar los pesos en cada capa de una MLP:\n",
        "\n",
        "1. **Cálculo de Error** en la capa de salida.  \n",
        "2. **Propagación** de ese error hacia capas anteriores.  \n",
        "3. **Regla de Actualización** de los pesos mediante descenso por gradiente.\n",
        "\n",
        "   La lógica se basa en la **regla de la cadena (chain rule)**:\n",
        "\n",
        "-  Cada neurona recibe parte de la “responsabilidad” del error total.  \n",
        "-  Las capas ocultas se actualizan después de que la capa de salida ya calculó su contribución al error.\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Algoritmo de Backpropagation\n",
        "\n",
        "::: {style=\"font-size:80%;\"}\n",
        "El **algoritmo en 7 pasos**. En resumen:\n",
        "\n",
        "1. **Inicializar** los pesos y bias con valores pequeños aleatorios.  \n",
        "2. **Forward Pass**: calcular sumas ponderadas y activaciones hasta la salida.  \n",
        "3. **Calcular el Error** (p. ej., error cuadrático).  \n",
        "4. **Calcular gradiente** en la capa de salida.  \n",
        "5. **Actualizar** los pesos de la última capa.  \n",
        "6. **Propagar** el error a la(s) capa(s) oculta(s) y actualizar sus pesos.  \n",
        "7. **Repetir** (Forward + Backward) hasta convergencia o hasta un máximo de etapas.\n",
        "\n",
        "A continuación detallamos cada paso con sus ecuaciones.\n",
        ":::\n",
        "\n",
        "## Pasos 1-2\n",
        "\n",
        "::: {style=\"font-size:75%;\"}\n",
        "### **Paso 1: Inicialización**\n",
        "- Se asignan valores aleatorios pequeños a $W_{ij}$ y a los bias $b_j$ de todas las capas.\n",
        "\n",
        "### **Paso 2: Forward Pass**\n",
        "- Para cada capa $k$, calculamos la suma ponderada:  \n",
        "  $$\n",
        "  U_j^{(k)} = \\sum_i \\Bigl(\\mathbf{X}_iW_{ij}^{(k)} \\,\\Bigr) + b_j^{(k)} \n",
        "  $$  \n",
        "  y luego la salida de cada neurona:  \n",
        "  $$\n",
        "  O_j^{(k)} = f\\bigl(U_j^{(k)}\\bigr).\n",
        "  $$\n",
        ":::\n",
        "## Pasos 3 al 4\n",
        "::: {style=\"font-size:80%;\"}\n",
        "### **Paso 3: Calcular la función de error**\n",
        " \n",
        "  $$\n",
        "  L = \\frac{1}{2}\\bigl(\\hat{y}_i - y_i\\bigr)^2.\n",
        "  $$\n",
        "  (La constante $1/2$ facilita la derivada.)\n",
        "\n",
        "### **Paso 4: Calcular el gradiente en la capa de salida**\n",
        "\n",
        "  $$\n",
        "  \\frac{\\partial L}{\\partial \\mathbf{W}} = \\dfrac{\\partial\\bigl(1/2(\\hat{y}_i - y_i)^2\\bigr)}{\\partial \\mathbf{W}}.\n",
        "  $$\n",
        ":::\n",
        "## Pasos 5 al 6\n",
        "::: {style=\"font-size:70%;\"}\n",
        "### **Paso 5: Actualizar los pesos de la última capa**\n",
        "- La regla de descenso por gradiente:  \n",
        "  $$\n",
        "  \\mathbf{W}_\\text{nuevo}=\\mathbf{W}_\\text{viejo}-\\alpha\\;\\frac{\\partial L}{\\partial \\mathbf{W}}\n",
        "  $$\n",
        "  \n",
        "### **Paso 6: Actualizar los pesos de la(s) capa(s) oculta(s) (Backpropagation)**\n",
        "1. Para cada neurona $p$ en la capa $(k-1)$:  \n",
        "   \n",
        "   $$\n",
        "  W_{ij}^{(k)}= W_{ij}^{(k)} - \\eta\\;\\delta_i^{(k)}\\; O_j^{(k-1)},\n",
        "  $$\n",
        "   \n",
        "    donde $\\eta$ es la tasa de aprendizaje y $O_i^{(k-1)}$ la salida de la neurona $i$ en la capa anterior. \n",
        "\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "::: {style=\"font-size:70%;\"}\n",
        "2. Actualizar pesos:  \n",
        "   $$\n",
        "   \\delta_{i}^{k}=O_i^{k}(1-O_i^{k})\\sum_{j=1}^{M_{k+1}} \\partial_j^{(k+1)} W_{ij}^{(k+1)}\n",
        "   \\\\\n",
        "   \\partial_{j}^{k}=O_j^{(k+1)}(1-O_j^{(k+1)})(O_j^{(k+1)}-y_j).\n",
        "   $$\n",
        "\n",
        "\n",
        "### **Paso 7: Repetir**\n",
        "- Se repite **forward pass + backward pass** por múltiples etapas, hasta convergencia o hasta el número máximo de iteraciones.\n",
        ":::\n",
        "\n",
        "## Presentación del Taller semana 2\n",
        "::: {style=\"font-size:80%;\"}\n",
        "# Taller Práctico: Entrenando MLP con scikit-learn y Keras\n",
        "\n",
        "En este taller cubriremos:\n",
        "\n",
        "1. **Clasificación binaria** usando **Wine Dataset** (scikit-learn).  \n",
        "2. **Clasificación binaria** con **Breast Cancer Dataset** (Keras).  \n",
        "3. Análisis de **número de neuronas**, **capas ocultas** y **tasa de aprendizaje**.\n",
        "\n",
        "Al final, tendremos una **comprensión práctica** de cómo configurar **Multi-Layer Perceptrons** y cómo los cambios en la arquitectura impactan la precisión y la pérdida.\n",
        ":::\n",
        "\n",
        "## Ejercicio 1 - Wine Dataset (scikit-learn)\n",
        "\n",
        "::: {style=\"font-size:80%;\"}\n",
        "\n",
        "**Objetivo**: Clasificar las dos primeras clases del dataset Wine (13 características, 130 muestras), y comparar dos MLP:\n",
        "\n",
        "-  Uno con **parámetros por defecto** (100 neuronas en la capa oculta).\n",
        "-  Otro con solo **3 neuronas** en la capa oculta.\n",
        "\n",
        "### Pasos Generales\n",
        "\n",
        "1. **Cargar** el dataset y filtrar las clases a usar.  \n",
        "2. **Separar** datos en entrenamiento y prueba (`train_test_split`).  \n",
        "3. **Definir** y **entrenar** dos modelos MLP (uno por defecto, otro con 3 neuronas).  \n",
        "4. **Comparar** precisión en el set de prueba.\n",
        "\n",
        "[**Ver código en GoogleColab Ejercicio 4_1**](https://colab.research.google.com/drive/1nnMZpwhRmqSus3_thtvy0ZQceS5V85Bz?authuser=1)\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "## Conclusiones Ejercicio 1\n",
        "\n",
        "::: {style=\"font-size:80%;\"}\n",
        "\n",
        "1. **Más neuronas** → mayor capacidad de ajuste → tiende a mejor desempeño (aunque no siempre).  \n",
        "2. Un número muy bajo de neuronas puede **subajustar** (underfitting).  \n",
        "3. Elección del tamaño de la capa oculta = **hiperparámetro** que depende del dataset y se suele ajustar de forma **empírica**.\n",
        "\n",
        "### **Tarea Sugerida**:\n",
        "- Prueba distintos tamaños de capa oculta: (10,), (50,), (200,).  \n",
        "- Observa cómo varía la precisión de prueba y el tiempo de entrenamiento.\n",
        ":::\n",
        "\n",
        "\n",
        "## Ejercicio 2 - Breast Cancer (Keras)\n",
        "\n",
        "::: {style=\"font-size:70%;\"}\n",
        "\n",
        "**Objetivo**: Utilizar la librería **Keras** para crear un MLP que clasifique el dataset de **Cáncer de Mama** (Breast Cancer).  \n",
        "- Modelo 1: 1 capa oculta (16 neuronas).  \n",
        "- Modelo 2: 2 capas ocultas (16 y 8 neuronas).\n",
        "\n",
        "Además, **experimentar** con optimizadores (SGD, RMSprop, Adam) y tasas de aprendizaje.\n",
        "\n",
        "### Pasos Generales\n",
        "1. Cargar `load_breast_cancer` (569 muestras, 30 features).  \n",
        "2. Separar en entrenamiento y prueba (`train_test_split`).  \n",
        "3. Definir un **Sequential** con `Dense(...)`.  \n",
        "4. Compilar el modelo (`model.compile(...)`) indicando el optimizador, la pérdida (`binary_crossentropy`) y la métrica (`accuracy`).  \n",
        "5. Entrenar (`model.fit(...)`) y evaluar (`model.evaluate(...)`).\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "## Código Ejercicio 2 (Keras, 1 capa oculta)\n",
        "\n",
        "[**Ver código en GoogleColab Ejercicio 4_2**](https://colab.research.google.com/drive/1x3oNyYN2n6nFkhVyQc_uy2KkHLDYbO_8?authuser=1)\n",
        "\n",
        "\n",
        "## Visualización de Resultados\n",
        "\n",
        "::: {style=\"font-size:80%;\"}\n",
        "Generalmente, se grafican:\n",
        "\n",
        "-  **Training vs. Validation Loss**  \n",
        "-  **Training vs. Validation Accuracy**\n",
        "\n",
        "\n",
        "Podemos ver si el modelo **sobreeentrena** (training accuracy sube y validation no mejora) o si converge adecuadamente.\n",
        ":::\n",
        "\n",
        "\n",
        "## Múltiples Capas Ocultas y Optimización\n",
        "\n",
        "::: {style=\"font-size:80%;\"}\n",
        "**Modelo 2**: 2 capas ocultas (16 y 8 neuronas).  \n",
        "\n",
        "-   [**Ver código en GoogleColab Ejercicio 4_3**](https://colab.research.google.com/drive/1p05uOEd0rSPrF4aT_weNLlIhCyggzjIN?authuser=1)\n",
        "-   [**Ver código en GoogleColab Ejercicio 4_4**](https://colab.research.google.com/drive/1T5g-BQUXDKA4IiwhVLd5TVGoELxwwwHQ?authuser=1#scrollTo=2R4aP9UiWkmO)\n",
        "-   [**Ver código en GoogleColab Ejercicio 4_5**](https://colab.research.google.com/drive/1RIVBByXg7LgwURINTE6_1AJoKtdUKvmJ?authuser=1#scrollTo=FZEXdBM6j0a2)\n",
        "-   [**Ver código en GoogleColab Ejercicio 4_6**](https://colab.research.google.com/drive/1cUgSQK6ELHRArIFZsG8ud5CPrBW_mdsq?authuser=1)\n",
        "\n",
        "        \n",
        "\n",
        "**Cambiar optimizador / LR** (ej. Adam con lr=0.001):\n",
        "\n",
        "\n",
        "**Observa** la variación de desempeño con distintas capas y optimizadores.\n",
        ":::\n",
        "\n",
        "\n",
        "## Tarea Final\n",
        "\n",
        "::: {style=\"font-size:70%;\"}\n",
        "1. **Experimentar con más etapas**: aumenta o reduce `epochs` (por ejemplo, 100, 200).  \n",
        "2. **Cambiar la función de activación**: `'relu'` en lugar de `'sigmoid'` entre otras.  \n",
        "3. **Variar el número de capas**:  \n",
        "   - 1 capa oculta (p.ej. 50 neuronas).  \n",
        "   - 2 capas ocultas (p.ej. 25 y 12).  \n",
        "4. **Monitorear** la pérdida y precisión en cada experimento.  \n",
        "5. **Comparar**: ¿Cuál configuración converge más rápido? ¿Cuál obtiene mejor exactitud?\n",
        "\n",
        "Al final, **documenta** tus hallazgos:\n",
        "- ¿Qué impacto tuvo la tasa de aprendizaje?  \n",
        "- ¿Cambió el problema de *overfitting*?\n",
        "\n",
        "¡Éxitos en tu exploración con MLPs!\n",
        ":::\n",
        "\n",
        "# Conclusiones y Debate\n",
        "\n",
        "::: {style=\"font-size:80%;\"}\n",
        "-   Hemos explorado desde la base del perceptrón y su inspiración biológica hasta la complejidad de sistemas de deep learning.\\\n",
        "-   Se ha destacado la importancia de las transformaciones no lineales para lograr la separación de datos complejos.\\\n",
        "-   La optimización mediante propagación hacia atrás y gradiente descendente es fundamental para ajustar los parámetros.\n",
        "-  **Número de neuronas** y **capas ocultas** son hiperparámetros cruciales.  \n",
        "-  **Tasa de aprendizaje** y **optimizador** pueden alterar la velocidad y estabilidad de convergencia.  \n",
        "- Para problemas reales, conviene **probar múltiples configuraciones** (grid search o random search), con validación cruzada.  \n",
        "\n",
        ":::\n",
        "\n",
        "# Referencias\n",
        "\n",
        "::: {style=\"font-size:80%;\"}\n",
        "1.  Definición informal de ML.\\\n",
        "2.  Definición de IA.\\\n",
        "3.  Definición formal de ML (Tom Mitchell).\\\n",
        "4.  Minsky, M. & Papert, S. (1969). *Perceptrons*. MIT Press.\\\n",
        "5.  Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). *Learning representations by back-propagating errors*. Nature, 323(6088), 533–536.\\\n",
        "6.  LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). *Gradient-based learning applied to document recognition*. Proceedings of the IEEE, 86(11), 2278–2324.\\\n",
        "7.  Hubel, D. H., & Wiesel, T. N. (1962). *Receptive fields, binocular interaction and functional architecture in the cat's visual cortex*. Journal of Physiology, 160, 106–154.\\\n",
        "8.  Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). *ImageNet classification with deep convolutional neural networks*. NeurIPS.\\\n",
        "9.  He, K., Zhang, X., Ren, S., & Sun, J. (2016). *Deep residual learning for image recognition*. CVPR.\\\n",
        "10. Material y figuras extraídos de: *Complemento Capítulo 3: Introduction to Deep Learning* :contentReference[oaicite:6]{index=\"6\"}.\n",
        "\n",
        "© Harsh Bhasin 2024\\\n",
        "H. Bhasin, *Hands-on Deep Learning*, [DOI:10.1007/979-8-8688-1035-0_1](https://doi.org/10.1007/979-8-8688-1035-0_1) \\`\\`\\`\n",
        "\n",
        ":::"
      ],
      "id": "a86aca5a"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}